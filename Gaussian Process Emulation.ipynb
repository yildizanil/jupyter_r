{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Process Emulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian process emulation has been in use since 1980s as a well-known non-parametric Bayesian method. It builds *cheap-to-run* emulators for *expensive-to-run* simulation models (referred to as simulators) so as to enable analyses requiring a large number of simulation runs.\n",
    "\n",
    "Given a simulator $y=f(x)$ with a $p$-dimensional input $x \\in \\mathbb{R}^{p}$ and scalar output $y \\in \\mathbb{R}$, the function $f(\\cdot)$ is treated as an unknown function. The prior belief of $f(\\cdot)$ is modeled by a Gaussian process, namely\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    f(\\cdot)\\sim \\mathcal{GP}(m(\\cdot;\\beta),C(\\cdot;\\cdot;\\sigma^{2},\\gamma))\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "The Gaussian process is fully defined by its mean function $m(\\cdot;\\beta)$ and covariance function $C(\\cdot;\\cdot;\\sigma^2,\\gamma)$, where $\\beta$, $\\sigma^2$, $\\gamma$ are unknown hyperparameters. This Gaussian process prior is then updated to a Gaussian process posterior based on input-output data $D$ of a modest number of simulation runs, known as training data. The output of the function at any new input can then be predicted almost instantaneously by\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    y^*|D,\\beta,\\sigma^2,\\gamma \\sim N(m´,\\sigma^{2}c´)\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where $m´$ and $c´$ are updated mean function and covariance function respectively. There are different ways to deal with the unknown hyperparameters $\\beta$, $\\sigma^2$, $\\gamma$, varying from non-Bayesian to fully Bayesian approaches. In this paper, we use the partially Bayesian approach which first integrates out $\\beta$, $\\sigma^2$ following the Bayesian way and then plugs in the maximum marginal posterior estimation of $\\gamma$ in a non-Bayesian way. In this case, the posterior given in Eq. \\ref{eq:eq2} is no longer a Gaussian process but a Student’s-t process, see \\citep{zhao2020emulatorbased} for detailed description.\n",
    "For multi-output simulators, such as the landslide run-out model, multivariate Gaussian process emulation is required. In this study, we use the parallel partial Gaussian process emulator developed by \\citep{Gu_Berger_2016}. Both the maximum marginal posterior estimation of $\\gamma$ and the parallel partial Gaussian process emulator have been implemented in the R package RobustGaSP, which was presented by \\citep{Gu_et_al_2019}. We combine it with the landslide run-out solver r.avaflow v2.3 in this study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will have a look at the [RobustGaSP](https://cran.r-project.org/web/packages/RobustGaSP/RobustGaSP.pdf) package by maintained by [Mengyang Gu](mailto:mengyang@pstat.ucsb.edu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'RobustGaSP' was built under R version 3.6.3\"#########\n",
      "##\n",
      "## Robust Gaussian Stochastic Process, RobustGaSP Package\n",
      "## Copyright (C) 2016-2022 Mengyang Gu, Jesus Palomo and James O. Berger\n",
      "#########\n",
      "\n",
      "Attaching package: 'RobustGaSP'\n",
      "\n",
      "The following object is masked from 'package:stats':\n",
      "\n",
      "    simulate\n",
      "\n",
      "Warning message:\n",
      "\"package 'lhs' was built under R version 3.6.3\""
     ]
    }
   ],
   "source": [
    "library(RobustGaSP)\n",
    "library(lhs)\n",
    "library(scatterplot3d)\n",
    "# dimensional of the inputs\n",
    "dim_inputs <- 3\n",
    "# number of the inputs\n",
    "num_obs <- 30\n",
    "# uniform samples of design\n",
    "input <- maximinLHS(n = num_obs, k = dim_inputs) ##maximin lhd sample"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wil generate output data using the curved function given in [Dette and Pepelyshev (2010)](https://doi.org/10.1198/TECH.2010.09157).\n",
    "\n",
    "$$\n",
    "f(x) = 4 (x_1 - 2 + 8x_2 - 8{x_2}^2)^2 + (3 - 4x_2)^2 + 16 \\sqrt{x_3 + 1}{(2x_3 - 1)}^2\n",
    "$$\n",
    "\n",
    "The function is evaluated on the cube for $x_1$, $x_2$ and $x_3$ between 0 and 1. We create an input data frame using the latin hypercube sampling method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>x1</th><th scope=col>x2</th><th scope=col>x3</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.6137628</td><td>0.1094040</td><td>0.5207374</td></tr>\n",
       "\t<tr><td>0.7856541</td><td>0.1355144</td><td>0.3154205</td></tr>\n",
       "\t<tr><td>0.5284009</td><td>0.8760465</td><td>0.8016871</td></tr>\n",
       "\t<tr><td>0.2915581</td><td>0.5301255</td><td>0.3443643</td></tr>\n",
       "\t<tr><td>0.5683302</td><td>0.2846974</td><td>0.7829776</td></tr>\n",
       "\t<tr><td>0.4409170</td><td>0.4294738</td><td>0.8105108</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{lll}\n",
       " x1 & x2 & x3\\\\\n",
       "\\hline\n",
       "\t 0.6137628 & 0.1094040 & 0.5207374\\\\\n",
       "\t 0.7856541 & 0.1355144 & 0.3154205\\\\\n",
       "\t 0.5284009 & 0.8760465 & 0.8016871\\\\\n",
       "\t 0.2915581 & 0.5301255 & 0.3443643\\\\\n",
       "\t 0.5683302 & 0.2846974 & 0.7829776\\\\\n",
       "\t 0.4409170 & 0.4294738 & 0.8105108\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| x1 | x2 | x3 |\n",
       "|---|---|---|\n",
       "| 0.6137628 | 0.1094040 | 0.5207374 |\n",
       "| 0.7856541 | 0.1355144 | 0.3154205 |\n",
       "| 0.5284009 | 0.8760465 | 0.8016871 |\n",
       "| 0.2915581 | 0.5301255 | 0.3443643 |\n",
       "| 0.5683302 | 0.2846974 | 0.7829776 |\n",
       "| 0.4409170 | 0.4294738 | 0.8105108 |\n",
       "\n"
      ],
      "text/plain": [
       "     x1        x2        x3       \n",
       "[1,] 0.6137628 0.1094040 0.5207374\n",
       "[2,] 0.7856541 0.1355144 0.3154205\n",
       "[3,] 0.5284009 0.8760465 0.8016871\n",
       "[4,] 0.2915581 0.5301255 0.3443643\n",
       "[5,] 0.5683302 0.2846974 0.7829776\n",
       "[6,] 0.4409170 0.4294738 0.8105108"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input <- maximinLHS(n = 100, k = 3)\n",
    "colnames(input) <- c(\"x1\", \"x2\", \"x3\")\n",
    "head(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dette_and_pepelyshev <- function(x1, x2, x3) {\n",
    "    term1 <- 4 * ((x1 - 2 + 8*x2 - 8 * (x2^2))^2)\n",
    "    term2 <- (3 - 4 * x2)^2\n",
    "    term3 <- 16 * sqrt(x3 + 1) * (2 * x3 - 1)^2\n",
    "    result <- term1 + term2 + term3\n",
    "    return(result)\n",
    "}\n",
    "output <- dette_and_pepelyshev(input[, 1], input[, 2], input[, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The upper bounds of the range parameters are Inf Inf Inf \n",
      "The initial values of range parameters are 0.009199126 0.009196666 0.009200836 \n",
      "Start of the optimization  1  : \n",
      "The number of iterations is  41 \n",
      " The value of the  marginal posterior  function is  36.27718 \n",
      " Optimized range parameters are 42.09951 13.1401 40.64215 \n",
      " Optimized nugget parameter is 0 \n",
      " Convergence:  FALSE \n",
      "The initial values of range parameters are 0.2752337 0.275139 0.2752996 \n",
      "Start of the optimization  2  : \n",
      "The number of iterations is  23 \n",
      " The value of the  marginal posterior  function is  36.25247 \n",
      " Optimized range parameters are 42.75381 13.35304 41.42685 \n",
      " Optimized nugget parameter is 0 \n",
      " Convergence:  TRUE \n"
     ]
    }
   ],
   "source": [
    "m1<- rgasp(design = input, response = output, lower_bound=FALSE)\n",
    "num_testing_input <- 1000\n",
    "# generate points to be predicted\n",
    "testing_input <- matrix(runif(num_testing_input*dim_inputs),num_testing_input,dim_inputs)\n",
    "# Perform prediction\n",
    "m1.predict<-predict(m1, testing_input, outasS3 = FALSE)\n",
    "# Predictive mean\n",
    "#m1.predict@mean\n",
    "# The following tests how good the prediction is\n",
    "testing_output <- matrix(0,num_testing_input,1)\n",
    "for(i in 1:num_testing_input){\n",
    "testing_output[i]<-dettepepel.3.data(testing_input[i,])\n",
    "}\n",
    "# compute the MSE, average coverage and average length\n",
    "# out of sample MSE\n",
    "MSE_emulator <- sum((m1.predict@mean-testing_output)^2)/(num_testing_input)\n",
    "# proportion covered by 95% posterior predictive credible interval\n",
    "prop_emulator <- length(which((m1.predict@lower95<=testing_output)\n",
    "&(m1.predict@upper95>=testing_output)))/num_testing_input\n",
    "# average length of posterior predictive credible interval\n",
    "length_emulator <- sum(m1.predict@upper95-m1.predict@lower95)/num_testing_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can watch an example of how to use Gaussian Process Emulation in emulating the output of landslide run-out simulations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  <a href=\"https://www.youtube.com/watch?v=BLdE9f5XOVM\"><img src=\"https://img.youtube.com/vi/BLdE9f5XOVM/0.jpg\" alt=\"IMAGE ALT TEXT\"></a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "80075ba2c5a16f292b1e32f3bef2800cd4060376ce6505b255826a9aa090387d"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
